/**
 * Meeting Transcription Process
 *
 * State machine for live meeting transcription + LLM summarization.
 *
 * Design:
 * - Feed entries are added by the Widget (this module never touches displayFeed)
 * - LLM is called with the accumulated text since the last call (not per-segment)
 * - MIN_ACCUMULATED_CHARS: don't waste an LLM call on tiny phrases
 * - STALE_TEXT_TIMEOUT_MS: fire anyway after silence even if text is short
 * - LLM_THROTTLE_MS: minimum gap between calls
 *
 * 3-level summary tree (depth = SUMMARY_TREE_DEPTH):
 *   overall  → big picture, changes slowly, preserves old context
 *   topic    → current major theme, changes when conversation shifts
 *   now      → latest exchange, updates every call
 *
 * Compaction rules (enforced in system prompt):
 *   - COMPACT, not summarise — preserve the original voice
 *   - No 3rd-person conversion: "I think..." stays "I think..."
 *   - Older important context must survive in `overall`
 *
 * Each level gets an LLM-generated Iconify icon for contextual visual feedback.
 *
 * Token budget worst-case (~2 K):
 *   overall   800 + topic 600 + now 400 = 1 800
 *   history   8 × 600                  = 4 800
 *   accum                              =   800
 *   overhead                           =   300
 *   ─────────────────────────────────────────
 *   total     ~7 700 chars ≈ ~1 925 tokens
 */

import { z } from 'zod';
import { callLLM } from '../../../program/llmClient';
import { parseLLMJSON } from '../../../program/utils/jsonUtils';
import { profileStorage } from '../../../lib/profileStorage';

// ============================================================================
// Constants
// ============================================================================

const STORAGE_KEY = 'meeting-transcription';
const ARCHIVE_STORAGE_KEY = 'meeting-transcription:archive';

/** Depth of the summary hierarchy. Change here + update SYSTEM_PROMPT if altered. */
export const SUMMARY_TREE_DEPTH = 3;

/** Min chars accumulated since last LLM call before we bother calling again */
export const MIN_ACCUMULATED_CHARS = 80;

/** After this ms of silence, fire LLM even if accumulated text is short */
export const STALE_TEXT_TIMEOUT_MS = 20_000;

const LLM_THROTTLE_MS = 8_000;
const MAX_HISTORY = 20;
const MAX_ARCHIVE = 10;
const LLM_HISTORY_WINDOW = 8;

/** Gap in ms after which a new recording-started is treated as a new meeting */
export const NEW_MEETING_GAP_MS = 3 * 60 * 1000;

// LLM input caps (see token budget comment above)
const MAX_OVERALL_CHARS = 800;
const MAX_TOPIC_CHARS   = 600;
const MAX_NOW_CHARS     = 400;
const MAX_HISTORY_SEGMENT_CHARS = 600;
const MAX_ACCUMULATED_TEXT_CHARS = 800;

// ============================================================================
// Types
// ============================================================================

export interface SummaryLevel {
  text: string;
  /** Iconify icon name generated by LLM, e.g. "mdi:target" */
  icon: string;
  updatedAt: number;
}

export interface SummaryTree {
  /** Big picture — why this meeting exists, key decisions. Changes slowly. */
  overall: SummaryLevel;
  /** Current major topic / phase. Changes when discussion shifts. */
  topic: SummaryLevel;
  /** Latest exchange right now. Updates every LLM call. */
  now: SummaryLevel;
}

export interface FeedEntry {
  id: string;
  text: string;
  audioType: 'mic' | 'system';
  ts: number;
}

export interface HistorySegment {
  text: string;
  audioType: 'mic' | 'system';
  ts: number;
}

export interface MeetingState {
  displayFeed: FeedEntry[];
  history: HistorySegment[];
  summaryTree: SummaryTree;
  nextStep: string;
  /** Iconify icon for the nextStep, generated by LLM. Empty = use fallback. */
  nextStepIcon: string;
  lastLLMCallAt: number;
  lastUpdatedAt: number;
  llmDurationMs: number;
  segmentCount: number;
  startedAt: number;
}

export interface ArchivedMeeting {
  id: string;
  startedAt: number;
  endedAt: number;
  /** overall.text at archive time */
  summary: string;
  nextStep: string;
  segmentCount: number;
}

export interface MeetingUpdateResult {
  state: MeetingState;
  llmRan: boolean;
}

// ============================================================================
// Zod schemas — used to validate data loaded from storage
// ============================================================================

const SummaryLevelSchema = z.object({
  text: z.string(),
  icon: z.string(),
  updatedAt: z.number(),
});

const SummaryTreeSchema = z.object({
  overall: SummaryLevelSchema,
  topic: SummaryLevelSchema,
  now: SummaryLevelSchema,
});

const FeedEntrySchema = z.object({
  id: z.string(),
  text: z.string(),
  audioType: z.enum(['mic', 'system']),
  ts: z.number(),
});

const HistorySegmentSchema = z.object({
  text: z.string(),
  audioType: z.enum(['mic', 'system']),
  ts: z.number(),
});

const MeetingStateSchema = z.object({
  displayFeed: z.array(FeedEntrySchema),
  history: z.array(HistorySegmentSchema),
  summaryTree: SummaryTreeSchema,
  nextStep: z.string(),
  nextStepIcon: z.string().default(''),
  lastLLMCallAt: z.number(),
  lastUpdatedAt: z.number(),
  llmDurationMs: z.number(),
  segmentCount: z.number(),
  startedAt: z.number(),
});

const ArchivedMeetingSchema = z.object({
  id: z.string(),
  startedAt: z.number(),
  endedAt: z.number(),
  summary: z.string(),
  nextStep: z.string(),
  segmentCount: z.number(),
});

// ============================================================================
// Storage
// ============================================================================

export function saveMeetingState(state: MeetingState): void {
  try {
    profileStorage.setJSON(STORAGE_KEY, state);
  } catch (error) {
    console.warn('[MeetingTranscription] Failed to save state:', error);
  }
}

export function loadMeetingState(): MeetingState | null {
  try {
    const raw = profileStorage.getJSON<unknown>(STORAGE_KEY);
    if (raw == null) return null;
    const result = MeetingStateSchema.safeParse(raw);
    if (!result.success) {
      console.warn('[MeetingTranscription] Stored state failed validation (schema changed?) — resetting:', result.error.issues);
      return null;
    }
    return result.data;
  } catch (error) {
    console.warn('[MeetingTranscription] Failed to load state:', error);
    return null;
  }
}

export function clearMeetingState(): void {
  try {
    profileStorage.removeItem(STORAGE_KEY);
  } catch { /* ignore */ }
}

export function loadArchivedMeetings(): ArchivedMeeting[] {
  try {
    const raw = profileStorage.getJSON<unknown>(ARCHIVE_STORAGE_KEY);
    if (raw == null) return [];
    const result = z.array(ArchivedMeetingSchema).safeParse(raw);
    if (!result.success) {
      console.warn('[MeetingTranscription] Stored archive failed validation — clearing:', result.error.issues);
      return [];
    }
    return result.data;
  } catch {
    return [];
  }
}

function saveArchivedMeetings(meetings: ArchivedMeeting[]): void {
  try {
    profileStorage.setJSON(ARCHIVE_STORAGE_KEY, meetings);
  } catch (error) {
    console.warn('[MeetingTranscription] Failed to save archive:', error);
  }
}

/** Archive the current meeting (if it has content). Returns updated archive list. */
export function archiveCurrentMeeting(state: MeetingState): ArchivedMeeting[] {
  if (state.segmentCount === 0) return loadArchivedMeetings();

  const archived: ArchivedMeeting = {
    id: `meeting-${state.startedAt}`,
    startedAt: state.startedAt,
    endedAt: Date.now(),
    summary: state.summaryTree.overall.text || '(no summary generated)',
    nextStep: state.nextStep,
    segmentCount: state.segmentCount,
  };

  const existing = loadArchivedMeetings();
  const deduplicated = existing.filter((m) => m.id !== archived.id);
  const updated = [archived, ...deduplicated].slice(0, MAX_ARCHIVE);
  saveArchivedMeetings(updated);
  return updated;
}

// ============================================================================
// Initial state
// ============================================================================

export function createInitialMeetingState(): MeetingState {
  return {
    displayFeed: [],
    history: [],
    summaryTree: {
      overall: { text: '', icon: 'mdi:flag-outline', updatedAt: 0 },
      topic:   { text: '', icon: 'mdi:comment-multiple-outline', updatedAt: 0 },
      now:     { text: '', icon: 'mdi:lightning-bolt-outline', updatedAt: 0 },
    },
    nextStep: '',
    nextStepIcon: '',
    lastLLMCallAt: 0,
    lastUpdatedAt: Date.now(),
    llmDurationMs: 0,
    segmentCount: 0,
    startedAt: Date.now(),
  };
}

// ============================================================================
// LLM Prompts
// ============================================================================

const SYSTEM_PROMPT = `You are a live meeting intelligence assistant maintaining a 3-level context tree.

AUDIO SOURCES:
- "mic" = the current user (microphone)
- "system" = other participants (system/screen audio)
ECHO WARNING: With speakers (not headphones) "system" may also appear as "mic". Use context to infer true speaker.

━━━ COMPACTION RULES (critical) ━━━
You COMPACT content — you do NOT summarise into 3rd-person narrative.
✗ WRONG: "The user discussed budget concerns with the team"
✓ RIGHT:  "Budget is tight — can't fund both projects this quarter"
• Preserve the original voice: keep "I think", "We need", "Let's", first-person intact
• Compress length, keep key facts, decisions, commitments, numbers
• The tree feeds back into itself — treat it as a recursive compaction loop

━━━ TREE LEVELS (depth = ${SUMMARY_TREE_DEPTH}) ━━━
1. OVERALL — The big picture. Why this meeting exists. Goals, decisions, commitments made.
   • PRESERVE old important context — it must survive even as meeting progresses
   • Only update when something fundamentally new happens
   • Max 120 words

2. TOPIC — Current major theme or phase of the conversation.
   • Update when discussion clearly shifts to a new area
   • Max 60 words

3. NOW — The most recent exchange. What is being said right now.
   • Always update with the latest content
   • Max 35 words

━━━ ICONS ━━━
For each level AND for the nextStep, generate a contextual Iconify icon (mdi: prefix).
The icon must reflect the actual content — not the level type — make it mentally satisfying.
Examples: "mdi:target", "mdi:handshake", "mdi:rocket-launch", "mdi:alert-circle", "mdi:lightbulb-outline",
          "mdi:calendar-check", "mdi:comment-question", "mdi:file-document-edit", "mdi:account-voice"

━━━ RESPONSE FORMAT (JSON only, no markdown) ━━━
{
  "overall": { "text": "...", "icon": "mdi:..." },
  "topic":   { "text": "...", "icon": "mdi:..." },
  "now":     { "text": "...", "icon": "mdi:..." },
  "nextStep": "one line, max 12 words, guide the user on what to do or say now",
  "nextStepIcon": "mdi:..."
}`;

function truncate(text: string, max: number): string {
  if (text.length <= max) return text;
  return text.slice(0, max) + '…';
}

function buildUserPrompt(
  state: MeetingState,
  accumulatedText: string,
  latestAudioType: 'mic' | 'system'
): string {
  const { summaryTree: tree } = state;

  const overallText  = tree.overall.text ? truncate(tree.overall.text, MAX_OVERALL_CHARS) : '(meeting just started)';
  const topicText    = tree.topic.text   ? truncate(tree.topic.text,   MAX_TOPIC_CHARS)   : '(no topic yet)';
  const nowText      = tree.now.text     ? truncate(tree.now.text,     MAX_NOW_CHARS)     : '(nothing yet)';

  const recentHistory = state.history
    .slice(-LLM_HISTORY_WINDOW)
    .map((s) => `[${s.audioType.toUpperCase()}] ${truncate(s.text, MAX_HISTORY_SEGMENT_CHARS)}`)
    .join('\n');

  const newContent = truncate(accumulatedText, MAX_ACCUMULATED_TEXT_CHARS);

  return `CURRENT TREE:
[OVERALL] ${overallText}
[TOPIC]   ${topicText}
[NOW]     ${nowText}

RECENT HISTORY (last segments):
${recentHistory || '(none yet)'}

NEW CONTENT TO COMPACT (audio type: ${latestAudioType.toUpperCase()}):
${newContent}

Update the tree. Compact don't summarise. Preserve voice. Preserve old context in OVERALL.`;
}

// ============================================================================
// State machine update
// ============================================================================

/**
 * Run an LLM update cycle with the text accumulated since the last call.
 *
 * The Widget owns:
 *  - displayFeed updates (done optimistically before calling here)
 *  - segmentCount updates
 *  - accumulation logic + throttle decision
 *
 * This function owns:
 *  - The LLM call
 *  - summaryTree + nextStep updates
 *  - history updates
 *  - lastLLMCallAt + llmDurationMs
 *  - profileStorage persistence
 *
 * The returned state spreads the input state, so displayFeed/segmentCount
 * from the Widget's latest stateRef are preserved.
 */
export async function processMeetingUpdate(
  state: MeetingState,
  accumulatedText: string,
  latestAudioType: 'mic' | 'system',
  forceImmediate = false
): Promise<MeetingUpdateResult> {
  const now = Date.now();
  const timeSinceLast = now - state.lastLLMCallAt;

  if (!forceImmediate && timeSinceLast < LLM_THROTTLE_MS) {
    return { state, llmRan: false };
  }

  const startTime = performance.now();
  try {
    const response = await callLLM({
      tier: 'medium',
      prompt: buildUserPrompt(state, accumulatedText, latestAudioType),
      systemPrompt: SYSTEM_PROMPT,
      options: { max_tokens: 650 },
    });

    const llmDurationMs = Math.round(performance.now() - startTime);
    const { data } = parseLLMJSON(response.content);

    // Start from the current tree — only overwrite levels that the LLM returned
    const newTree: SummaryTree = {
      overall: { ...state.summaryTree.overall },
      topic:   { ...state.summaryTree.topic },
      now:     { ...state.summaryTree.now },
    };
    let newNextStep = state.nextStep;
    let newNextStepIcon = state.nextStepIcon;

    if (data && typeof data === 'object') {
      const obj = data as Record<string, unknown>;

      for (const level of ['overall', 'topic', 'now'] as const) {
        const raw = obj[level];
        if (raw && typeof raw === 'object') {
          const l = raw as Record<string, unknown>;
          if (typeof l.text === 'string' && l.text.trim()) {
            newTree[level] = {
              text: l.text.trim(),
              icon: typeof l.icon === 'string' && l.icon.trim() ? l.icon.trim() : newTree[level].icon,
              updatedAt: now,
            };
          }
        }
      }

      if (typeof obj.nextStep === 'string' && obj.nextStep.trim()) {
        newNextStep = obj.nextStep.trim();
      }

      if (typeof obj.nextStepIcon === 'string' && obj.nextStepIcon.trim().includes(':')) {
        newNextStepIcon = obj.nextStepIcon.trim();
      }
    }

    // Add accumulated text to history as a single compacted entry
    const historyEntry: HistorySegment = {
      text: truncate(accumulatedText, MAX_HISTORY_SEGMENT_CHARS),
      audioType: latestAudioType,
      ts: now,
    };
    const updatedHistory = [...state.history, historyEntry];
    if (updatedHistory.length > MAX_HISTORY) {
      updatedHistory.splice(0, updatedHistory.length - MAX_HISTORY);
    }

    const newState: MeetingState = {
      ...state,                 // preserves displayFeed, segmentCount, startedAt, etc.
      history: updatedHistory,
      summaryTree: newTree,
      nextStep: newNextStep,
      nextStepIcon: newNextStepIcon,
      lastLLMCallAt: now,
      llmDurationMs,
    };

    saveMeetingState(newState);
    return { state: newState, llmRan: true };
  } catch (error) {
    console.error('[MeetingTranscription] LLM call failed:', error);
    return { state: { ...state, lastLLMCallAt: now }, llmRan: false };
  }
}
